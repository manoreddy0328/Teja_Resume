# About me

Hello, I'm Mano Teja Reddy, a DevOps Engineer with 6+ years of experience. My expertise lies primarily in Azure, and I have also worked extensively with AWS and GCP. I excel in using GIT, MAVEN, and Jenkins for CI, and Docker/Kubernetes for CD. My skills include developing end-to-end CICD pipelines and managing containers with Kubernetes.In addition to my proficiency in Azure, I have had the opportunity to work on various AWS services, such as VPC, EC2, and S3, leveraging the cloud's power for efficient data storage and application deployment. Moreover, I have successfully deployed micro-services applications on AWS Cloud using EKS (Elastic Kubernetes Service).Furthermore, my experience extends to Google Cloud Platform (GCP), where I have gained valuable insights into cloud-based solutions and services.


I am passionate about keeping up-to-date of the latest advancements in the DevOps landscape and always eager to explore new challenges. My dedication to delivering high-quality solutions and driving continuous improvement makes me a valuable asset to any project.

Looking forward to connecting and collaborating on exciting ventures that push the boundaries of technology.

# Few Projects I worked on

# 1. Project Details: Continuous delivery pipeline for a Custom -Built Application
I worked with a team of 8 developers and 3 QA engineers. My role as a DevOps Engineer was to design and implement a continuous delivery pipeline for the custom-built application that our team was developing. The pipeline included source control, build automation, testing, and deployment to different environments.
As part of the project, I also worked with the development team to ensure that the code was modular and scalable. This required me to create a set of guidelines and best practices for the development team to follow. Additionally, I collaborated with the infrastructure team to ensure that the necessary infrastructure was in place to support the application's deployment.
To achieve our goals, we used various team collaboration tools such as JIRA, Confluence, and Slack. We also used GitLab for source control, Jenkins for build automation, and Ansible for deployment automation.
The application was designed to handle a large volume of customers data, which made it quite complex. The application had to integrate with multiple Banking systems, including electronic records. Our team worked diligently to ensure that the application was highly available, scalable, and secure.
The application's benefits were significant for Client, as it enabled them to provide better data by providing transaction details with more accurate and timely information. Additionally, it streamlined their billing process and reduced the risk of errors. The technologies and tools we used included Java, Spring Boot, Docker, Kubernetes, and AWS.

# Project 2: Migrate their monolithic application to a microservices-based architecture.
Our client wanted to migrate their monolithic application to a microservices-based architecture, So here we started containerizing the application and deploying it in a Kubernetes cluster. My role was to manage the production environment for this application. I worked closely with the development team and operations team so that the application was deployed correctly and manage the Kubernetes cluster.
I set up a continuous delivery pipeline using Jenkins, which built the Docker images for the application and pushed them to a private Docker registry. I then used Helm charts to deploy the application to the Kubernetes cluster. I also set up monitoring using Prometheus and Grafana and implemented autoscaling for the application based on resource utilization.
Collaboration Tools:
We used Jira for project management and Slack for real-time communication. We also used GitHub for version control and code reviews.
Complexity/Size/Scale/User Benefits/Technologies/Tools Used:
The application was little complex it consists of multiple microservices, and required several Kubernetes resources to be deployed (deployments, services, ingresses, config maps, and secrets). The cluster was a medium-sized one, with around 20 worker nodes. The benefits to the user were improved performance, scalability, and reliability. Technologies used included Kubernetes, Docker, Helm, Jenkins, Prometheus, and Grafana. We also used Terraform to manage the infrastructure.





